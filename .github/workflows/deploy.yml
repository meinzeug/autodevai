name: Deploy

on:
  push:
    branches: [ main ]
    tags: [ 'v*' ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deploy environment'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production
      version:
        description: 'Version tag (optional)'
        required: false
        type: string

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  NODE_VERSION: '18'
  DOCKER_PORT_RANGE: '50000-50100'

jobs:
  build-docker:
    name: Build Docker Images
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    outputs:
      image-digest: ${{ steps.build.outputs.digest }}
      image-tag: ${{ steps.meta.outputs.tags }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64,linux/arm64
          build-args: |
            NODE_VERSION=${{ env.NODE_VERSION }}
            PORT_RANGE=${{ env.DOCKER_PORT_RANGE }}

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: build-docker
    environment: staging
    if: github.ref == 'refs/heads/main' || (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'staging')
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-2

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --region us-west-2 --name autodev-staging-cluster

      - name: Deploy to staging
        run: |
          # Replace image in deployment manifest
          sed -i 's|IMAGE_TAG|${{ needs.build-docker.outputs.image-tag }}|g' k8s/staging/deployment.yaml
          
          # Apply Kubernetes manifests
          kubectl apply -f k8s/staging/namespace.yaml
          kubectl apply -f k8s/staging/configmap.yaml
          kubectl apply -f k8s/staging/secret.yaml
          kubectl apply -f k8s/staging/deployment.yaml
          kubectl apply -f k8s/staging/service.yaml
          kubectl apply -f k8s/staging/ingress.yaml
          
          # Wait for deployment
          kubectl rollout status deployment/autodev-ai -n autodev-staging --timeout=300s

      - name: Run deployment tests
        run: |
          # Wait for service to be ready
          kubectl wait --for=condition=ready pod -l app=autodev-ai -n autodev-staging --timeout=300s
          
          # Get service endpoint
          STAGING_URL=$(kubectl get ingress autodev-ai-ingress -n autodev-staging -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          echo "Staging URL: https://$STAGING_URL"
          
          # Basic health check
          curl -f "https://$STAGING_URL/health" || exit 1
          curl -f "https://$STAGING_URL/api/v1/status" || exit 1

      - name: Run integration tests
        run: |
          npm ci
          npm run test:integration:staging
        env:
          STAGING_API_URL: ${{ secrets.STAGING_API_URL }}
          STAGING_API_KEY: ${{ secrets.STAGING_API_KEY }}

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [build-docker, deploy-staging]
    environment: production
    if: startsWith(github.ref, 'refs/tags/v') || (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'production')
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-2

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --region us-west-2 --name autodev-production-cluster

      - name: Create production deployment
        run: |
          # Replace image in deployment manifest
          sed -i 's|IMAGE_TAG|${{ needs.build-docker.outputs.image-tag }}|g' k8s/production/deployment.yaml
          
          # Apply Kubernetes manifests with rolling update
          kubectl apply -f k8s/production/namespace.yaml
          kubectl apply -f k8s/production/configmap.yaml
          kubectl apply -f k8s/production/secret.yaml
          kubectl apply -f k8s/production/deployment.yaml
          kubectl apply -f k8s/production/service.yaml
          kubectl apply -f k8s/production/ingress.yaml
          kubectl apply -f k8s/production/hpa.yaml
          
          # Wait for deployment
          kubectl rollout status deployment/autodev-ai -n autodev-production --timeout=600s

      - name: Run production health checks
        run: |
          # Wait for all pods to be ready
          kubectl wait --for=condition=ready pod -l app=autodev-ai -n autodev-production --timeout=300s
          
          # Get production endpoint
          PROD_URL=$(kubectl get ingress autodev-ai-ingress -n autodev-production -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          echo "Production URL: https://$PROD_URL"
          
          # Comprehensive health checks
          curl -f "https://$PROD_URL/health" || exit 1
          curl -f "https://$PROD_URL/api/v1/status" || exit 1
          curl -f "https://$PROD_URL/api/v1/metrics" || exit 1

      - name: Run production smoke tests
        run: |
          npm ci
          npm run test:smoke:production
        env:
          PRODUCTION_API_URL: ${{ secrets.PRODUCTION_API_URL }}
          PRODUCTION_API_KEY: ${{ secrets.PRODUCTION_API_KEY }}

      - name: Update monitoring dashboards
        run: |
          # Update Grafana dashboards
          curl -X POST "${{ secrets.GRAFANA_API_URL }}/api/dashboards/db" \
            -H "Authorization: Bearer ${{ secrets.GRAFANA_API_TOKEN }}" \
            -H "Content-Type: application/json" \
            -d @monitoring/grafana-dashboard.json

      - name: Send deployment notification
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#deployments'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
          fields: repo,message,commit,author,action,eventName,ref,workflow
        if: always()

  rollback:
    name: Rollback Deployment
    runs-on: ubuntu-latest
    environment: production
    if: failure()
    needs: [deploy-production]
    steps:
      - name: Setup kubectl
        uses: azure/setup-kubectl@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-2

      - name: Rollback production deployment
        run: |
          aws eks update-kubeconfig --region us-west-2 --name autodev-production-cluster
          kubectl rollout undo deployment/autodev-ai -n autodev-production
          kubectl rollout status deployment/autodev-ai -n autodev-production --timeout=300s

      - name: Send rollback notification
        uses: 8398a7/action-slack@v3
        with:
          status: 'warning'
          channel: '#deployments'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
          text: 'ðŸš¨ Production deployment rolled back due to failure'

  cleanup:
    name: Cleanup Old Deployments
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: success()
    steps:
      - name: Setup kubectl
        uses: azure/setup-kubectl@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-2

      - name: Cleanup old replica sets
        run: |
          aws eks update-kubeconfig --region us-west-2 --name autodev-production-cluster
          
          # Keep only the latest 3 replica sets
          kubectl get rs -n autodev-production -o json | \
            jq -r '.items | sort_by(.metadata.creationTimestamp) | reverse | .[3:] | .[] | .metadata.name' | \
            xargs -r kubectl delete rs -n autodev-production

      - name: Cleanup old container images
        run: |
          # Delete images older than 30 days
          docker system prune -a -f --filter "until=720h"